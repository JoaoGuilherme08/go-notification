version: "3.3"

services:
  #  Zookeepers
  zookeeper:
    image: zookeeper:3.7.0
    restart: always
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      JVMFLAGS: -Xmx512m
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181
      ZOO_4LW_COMMANDS_WHITELIST: "*"
    healthcheck:
      test: [ "CMD-SHELL", "echo ruok | nc -w 2 zookeeper 2181" ]
      interval: 5s
      timeout: 3s
      retries: 2
    logging:
      options:
        max-size: "512k"
        max-file: "10"

  #kafka broker
  kafka1:
    image: confluentinc/cp-kafka:6.2.0
    hostname: kafka1
    depends_on:
      - zookeeper
    ports:
      - "19092:19092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092,PLAINTEXT_HOST://localhost:19092
      KAFKA_BROKER_ID: 1
      KAFKA_BROKER_RACK: "r1"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_SCHEMA_REGISTRY_URL: "schema-registry:8085"
      KAFKA_LOG_DIRS: "/var/lib/kafka/data1_0"
      KAFKA_JMX_PORT: 9991
      KAFKA_HEAP_OPTS: -Xmx1512M -Xms1512M
    logging:
      options:
        max-size: "512k"
        max-file: "10"

  kafka2:
    image: confluentinc/cp-kafka:6.2.0
    hostname: kafka2
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_BROKER_ID: 2
      KAFKA_BROKER_RACK: "r2"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_SCHEMA_REGISTRY_URL: "schema-registry:8085"
      KAFKA_LOG_DIRS: "/var/lib/kafka/data2_0"
      KAFKA_JMX_PORT: 9991
      KAFKA_HEAP_OPTS: -Xmx1512M -Xms1512M
    logging:
      options:
        max-size: "512k"
        max-file: "10"

  kafka3:
    image: confluentinc/cp-kafka:6.2.0
    hostname: kafka3
    depends_on:
      - zookeeper
    ports:
      - "39092:39092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka3:9092,PLAINTEXT_HOST://localhost:39092
      KAFKA_BROKER_ID: 3
      KAFKA_BROKER_RACK: "r3"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_SCHEMA_REGISTRY_URL: "schema-registry:8085"
      KAFKA_LOG_DIRS: "/var/lib/kafka/data3_0"
      KAFKA_JMX_PORT: 9991
      KAFKA_HEAP_OPTS: -Xmx1512M -Xms1512M
    logging:
      options:
        max-size: "512k"
        max-file: "10"

  #Schema Registry
  schema-registry:
    image: confluentinc/cp-schema-registry:6.2.0
    hostname: schema-registry
    depends_on:
      - zookeeper
      - kafka1
      - kafka2
      - kafka3
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: "zookeeper:2181"
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
    logging:
      options:
        max-size: "512k"
        max-file: "10"

  connect:
    image: confluentinc/cp-kafka-connect:6.2.0
    depends_on:
      - zookeeper
      - kafka1
      - kafka2
      - kafka3
      - schema-registry
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka1:9092,kafka2:9092,kafka3:9092
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_KEY_CONVERTER: 'org.apache.kafka.connect.storage.StringConverter'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "connect"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "ERROR"
      CONNECT_VALUE_CONVERTER_AUTO_REGISTER_SCHEMAS: "false"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "2"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "2"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "2"
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components,/data/connect-jars'
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: 'All'
    command:
      - bash
      - -c
      - |
        echo "Installing Connector"
        confluent-hub install  --no-prompt confluentinc/kafka-connect-avro-converter:7.1.1
        confluent-hub install  --no-prompt confluentinc/kafka-connect-jdbc:10.5.0
        confluent-hub install  --no-prompt confluentinc/connect-transforms:latest
        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run &
        #
        sleep infinity
    logging:
      options:
        max-size: "512k"
        max-file: "10"
    healthcheck:
      test: [ "CMD-SHELL", "curl localhost:8083/connectors" ]
      interval: 5s
      timeout: 3s
      retries: 2

  kafka-ui:
    image: provectuslabs/kafka-ui
    depends_on:
      - zookeeper
      - kafka1
      - kafka2
      - kafka3
      - schema-registry
      - connect
    ports:
      - "19000:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: kafka
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka1:9092,kafka2:9092,kafka3:9092"
      KAFKA_CLUSTERS_0_ZOOKEEPER: "zookeeper:2181"
      KAFKA_CLUSTERS_0_schema-registry: "http://schema-registry:8081"
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: "connect"
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: "http://connect:8083"
      KAFKA_CLUSTERS_0_JMXPORT: 9875
      KAFKA_CLUSTERS_0_JMXSSL: "false"
    logging:
      options:
        max-size: "512k"
        max-file: "10"